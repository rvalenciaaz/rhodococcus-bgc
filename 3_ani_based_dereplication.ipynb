{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "from shutil import rmtree\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import subprocess\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "from functools import reduce\n",
    "import operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_file\n",
    "from bokeh.models import Legend, LegendItem, Plot, Range1d, MultiLine, Circle, HoverTool, TapTool, BoxSelectTool, SaveTool, BoxZoomTool, WheelZoomTool, PanTool\n",
    "from bokeh.models.graphs import from_networkx, NodesAndLinkedEdges, EdgesAndLinkedNodes\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.core.properties import field\n",
    "\n",
    "from bokeh.layouts import widgetbox\n",
    "from bokeh.models.widgets import Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimo=1e-18\n",
    "maximo=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv('v2_edges_06_after_cleaning_checkcontrol.csv')\n",
    "b=a[(a['Raw distance']<maximo)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=pd.read_csv('edges_06_all.csv')\n",
    "b=a[(a['Raw distance']==a.iloc[761,2])&(a['Source']!=a['Target'])&(a['Raw distance']>=minimo)&(a['Raw distance']<maximo)]\n",
    "b.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=b.copy()\n",
    "new.loc[:,'Source']=new['Source'].apply(lambda x:x.split('.')[0]+'.1')\n",
    "new.loc[:,'Target']=new['Target'].apply(lambda x:x.split('.')[0]+'.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bex=new.copy()\n",
    "bex=bex[['Source','Target']]\n",
    "bex.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bex[bex.isnull().any(axis=1)]\n",
    "#comp=bex.apply(np.sort, axis = 1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp=bex.apply(lambda r: sorted(r), axis = 1).drop_duplicates()\n",
    "comp2=comp[comp['Target']!=comp['Source']]\n",
    "comp3=comp2.reset_index(drop=True)\n",
    "#inflexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "with open('rhodo_dictionary_file_code.pkl', 'wb') as f:\n",
    "    pickle.dump(din, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"rhodo_dictionary_file_code.pkl\",\"rb\") as p:\n",
    "#    din=pickle.load(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cou=1\n",
    "for index,row in comp3.iterrows():\n",
    "    print(row['Source'],row['Target'])\n",
    "    pix=0\n",
    "    for key,value in din.items():    \n",
    "        if row['Source'] in value:\n",
    "            sou=key\n",
    "            pix=pix+1\n",
    "        if row['Target'] in value:\n",
    "            tar=key\n",
    "            pix=pix+1\n",
    "        if pix==2:\n",
    "            break\n",
    "    print(sou,tar)\n",
    "    del sou,tar\n",
    "    print(cou)\n",
    "    cou=cou+1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results=[]\n",
    "dst='temp'\n",
    "count=1\n",
    "for index,row in comp3.iterrows():\n",
    "    #print(row['Source'])\n",
    "    pix=0\n",
    "    for key,value in din.items():\n",
    "        if row['Source'] in value:\n",
    "            sou=key\n",
    "            pix=pix+1\n",
    "        if row['Target'] in value:\n",
    "            tar=key\n",
    "            pix=pix+1\n",
    "        if pix==2:\n",
    "            break\n",
    "    copyfile('rhodococcusall/'+sou, dst+'/'+sou)\n",
    "    copyfile('rhodococcusall/'+tar, dst+'/'+tar)\n",
    "    \n",
    "    SeqIO.convert((dst+'/'+sou),'genbank',(dst+'/'+sou)[0:-4]+'fna','fasta')\n",
    "    SeqIO.convert((dst+'/'+tar),'genbank',(dst+'/'+tar)[0:-4]+'fna','fasta')\n",
    "    \n",
    "    command = 'average_nucleotide_identity.py -i temp/ -o temp/output -m ANIb'\n",
    "    process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    u=pd.read_table(dst+'/output/ANIb_percentage_identity.tab')\n",
    "    results.append(u.iloc[1,1])\n",
    "    \n",
    "    os.remove((dst+'/'+sou))\n",
    "    os.remove((dst+'/'+tar))\n",
    "    os.remove((dst+'/'+sou)[0:-4]+'fna')\n",
    "    os.remove((dst+'/'+tar)[0:-4]+'fna')\n",
    "    rmtree(dst+'/output')\n",
    "    #print(count)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#results=[]\n",
    "def analisis(row,nume):\n",
    "    dst='temp'+str(nume)\n",
    "    pix=0\n",
    "    for key,value in din.items():\n",
    "        if row['Source'] in value:\n",
    "            sou=key\n",
    "            pix=pix+1\n",
    "        if row['Target'] in value:\n",
    "            tar=key\n",
    "            pix=pix+1\n",
    "        if pix==2:\n",
    "            break\n",
    "    os.mkdir(dst)\n",
    "    copyfile('rhodococcusall/'+sou, dst+'/'+sou)\n",
    "    copyfile('rhodococcusall/'+tar, dst+'/'+tar)\n",
    "    \n",
    "    SeqIO.convert((dst+'/'+sou),'genbank',(dst+'/'+sou)[0:-4]+'fna','fasta')\n",
    "    SeqIO.convert((dst+'/'+tar),'genbank',(dst+'/'+tar)[0:-4]+'fna','fasta')\n",
    "    \n",
    "    command = 'average_nucleotide_identity.py -i '+dst+'/ -o '+dst+'/output -m ANIb'\n",
    "    process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    u=pd.read_table(dst+'/output/ANIb_percentage_identity.tab')\n",
    "    \n",
    "    \n",
    "    os.remove((dst+'/'+sou))\n",
    "    os.remove((dst+'/'+tar))\n",
    "    os.remove((dst+'/'+sou)[0:-4]+'fna')\n",
    "    os.remove((dst+'/'+tar)[0:-4]+'fna')\n",
    "    rmtree(dst)\n",
    "    \n",
    "    return (row['Source'],row['Target'],u.iloc[1,1])\n",
    "    #print(count)\n",
    "    #count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=Parallel(n_jobs=4)(delayed(analisis)(row,index) for index,row in comp3.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('valuesANIb.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"valuesANIb_cleaning.pkl\",\"rb\") as p:\n",
    "    values=pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sono=[i[0] for i in values]\n",
    "tano=[i[1] for i in values]\n",
    "val=[i[2] for i in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores=pd.DataFrame({'Source':sono,'Target':tano,'ANIb':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valorestmp=valores.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valorestmp['sourcegenome']=valorestmp['Source'].apply(lambda x:dr1[dr2[x]])\n",
    "valorestmp['targetgenome']=valorestmp['Target'].apply(lambda x:dr1[dr2[x]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valorestmp2=valorestmp[['sourcegenome','targetgenome','ANIb']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valorestmp3=valorestmp2.drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valorestmp3.to_excel('diccionario_ani_cleaning.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp4=comp3.merge(valores,how='left')\n",
    "#comp3=comp3.assign(ANIb=[i[1] for i in values])\n",
    "comp4.columns=['genome1','genome2','ANIb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.assign(genome1=h['Source'].apply(lambda x:x.split('.')[0]+'.1'))\n",
    "h = h.assign(genome2=h['Target'].apply(lambda x:x.split('.')[0]+'.1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2=h.merge(comp4,how='outer',on=['genome1','genome2'])\n",
    "b3=b2.copy()\n",
    "b3.drop(['genome1','genome2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3.loc[b3.isnull().any(axis=1),['ANIb']]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3.columns=['Source','Target','Distance','ANIb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo98=b3.loc[b3['ANIb']>0.98]\n",
    "#forbid98=tempo98['Target'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Distance</th>\n",
       "      <th>ANIb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NZ_NOZK01000025.cluster017</td>\n",
       "      <td>NZ_NOZK01000025.cluster020</td>\n",
       "      <td>4.163336e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NZ_NOZK01000025.cluster018</td>\n",
       "      <td>NZ_NOZK01000025.cluster019</td>\n",
       "      <td>4.163336e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NZ_LYPG01000001.cluster004</td>\n",
       "      <td>NZ_LYPG01000001.cluster005</td>\n",
       "      <td>4.163336e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NZ_NOYS01000019.cluster011</td>\n",
       "      <td>NZ_NOYS01000019.cluster012</td>\n",
       "      <td>4.163336e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NZ_NOYS01000019.cluster003</td>\n",
       "      <td>NZ_NOYS01000019.cluster004</td>\n",
       "      <td>2.955083e-04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Source                      Target      Distance  ANIb\n",
       "6   NZ_NOZK01000025.cluster017  NZ_NOZK01000025.cluster020  4.163336e-17   1.0\n",
       "7   NZ_NOZK01000025.cluster018  NZ_NOZK01000025.cluster019  4.163336e-17   1.0\n",
       "23  NZ_LYPG01000001.cluster004  NZ_LYPG01000001.cluster005  4.163336e-17   1.0\n",
       "24  NZ_NOYS01000019.cluster011  NZ_NOYS01000019.cluster012  4.163336e-17   1.0\n",
       "25  NZ_NOYS01000019.cluster003  NZ_NOYS01000019.cluster004  2.955083e-04   1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempo98.sort_values('ANIb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis=tempo98.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis=analisis[analisis['Source']!=analisis['Target']].sort_values('ANIb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis2=analisis[['Source','Target','ANIb']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis2.loc[:,'Source']=analisis2['Source'].apply(lambda x:x.split('.')[0]+'.1')\n",
    "analisis2.loc[:,'Target']=analisis2['Target'].apply(lambda x:x.split('.')[0]+'.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis3=analisis2[analisis2['Source']!=analisis2['Target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('rhodo_assembly_name.pkl','rb') as d1:\n",
    "    dr1=pickle.load(d1)\n",
    "with open('rhodo_contig_genome_dict.pkl','rb') as d2:\n",
    "    dr2=pickle.load(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gt=nx.from_pandas_edgelist(analisis3,source='Source',target='Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def contarcontig(namefile):\n",
    "    cou1=[1 for yi in SeqIO.parse(namefile,'genbank')]\n",
    "    cou2=[len(yi) for yi in SeqIO.parse(namefile,'genbank')]\n",
    "    contigs=sum(cou1)\n",
    "    largo=sum(cou2)\n",
    "    return contigs,largo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fg=[]\n",
    "lg=[]\n",
    "for fr in nx.nodes(gt):\n",
    "    do,lag=contarcontig('rhodococcusall/'+dr2[fr]+'_genomic.gbff')\n",
    "    fg.append(do)\n",
    "    lg.append(lag)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f=lambda x:dr1[dr2[x]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nx.set_node_attributes(gt, dict(zip(nx.nodes(gt),fg)),'contigs')\n",
    "nx.set_node_attributes(gt, dict(zip(nx.nodes(gt),list(map(f,nx.nodes(gt))))),'nombre')\n",
    "nx.set_node_attributes(gt, dict(zip(nx.nodes(gt),lg)),'largo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nx.get_node_attributes(gt,'nombre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ghu=pd.read_csv('Lista_final_editada_20190128.csv',sep=';',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ghusolo=ghu.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ghusolo2=ghusolo.apply(lambda x:dr1[x[0:-8]]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gt2=gt.subgraph([x for x,y in gt.nodes(data=True) if not(y['nombre'] in ghusolo2)]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#analisis2['sourcegenome']=analisis2['Source'].apply(lambda x:dr1[dr2[x]])\n",
    "#analisis2['targetgenome']=analisis2['Target'].apply(lambda x:dr1[dr2[x]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#analisis3=analisis2[['sourcegenome','targetgenome','ANIb']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#analisis4=analisis3.drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#analisis4.to_excel('listasobre98_154genomas.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for fr in nx.nodes(gt):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ansis=pd.unique(analisis['Source'].append(analisis['Target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ansis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrievebest(dictio):\n",
    "    nog=[]\n",
    "    maximo=max(list(dictio.values()))\n",
    "    for key, value in dictio.items():\n",
    "        if value==maximo:\n",
    "            nog.append(key)\n",
    "    return nog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iscomplete(graph):\n",
    "    nn=nx.number_of_nodes(graph)\n",
    "    ne=nx.number_of_edges(graph)\n",
    "    if nn*(nn-1)/2==ne:\n",
    "        return True\n",
    "    else:\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=nx.from_pandas_edgelist(tempo98,source='Source',target='Target',edge_attr='Distance')\n",
    "tmpg=sorted(nx.connected_component_subgraphs(q),key=len,reverse=True)\n",
    "listcon=sorted(nx.connected_components(q), key = len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete=[]\n",
    "noncomplete=[]\n",
    "for i in tmpg:\n",
    "    nn=nx.number_of_nodes(i)\n",
    "    ne=nx.number_of_edges(i)\n",
    "    if nn*(nn-1)/2==ne:\n",
    "        complete.append(i.copy())\n",
    "    else:\n",
    "        noncomplete.append(i.copy())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete=sorted(complete,key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncomplete=sorted(noncomplete,key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(complete))\n",
    "print(len(noncomplete))\n",
    "for nt in complete:\n",
    "    print(len(nx.nodes(nt)))\n",
    "for nt in noncomplete:\n",
    "    print(len(nx.nodes(nt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "{'NZ_NOYS01000019.cluster011': 40691, 'NZ_NOYS01000019.cluster012': 40690}\n",
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "saved=[]\n",
    "cou1=1\n",
    "for ty in tmpg:\n",
    "    dicyo={}\n",
    "    for i in list(ty.nodes()):\n",
    "        qx=SeqIO.read('clusters/'+i+'.gbk','genbank')\n",
    "        largo=len(qx)\n",
    "        dicyo[i]=largo\n",
    "    sob=random.choice(retrievebest(dicyo))\n",
    "    comprob=(len(set(list(dicyo.values())))==1)\n",
    "    print(comprob)\n",
    "    if not(comprob):\n",
    "        print(dicyo)\n",
    "        print(cou1)\n",
    "        cou1=cou1+1\n",
    "    saved.append(sob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(saved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "elimin=set(nx.nodes(q)).difference(set(saved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NZ_LYPG01000001.cluster005',\n",
       " 'NZ_NOYS01000019.cluster004',\n",
       " 'NZ_NOYS01000019.cluster012',\n",
       " 'NZ_NOZK01000025.cluster017',\n",
       " 'NZ_NOZK01000025.cluster018'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elimin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved=[]\n",
    "cou1=1\n",
    "for ty in complete:\n",
    "    dicyo={}\n",
    "    for i in list(ty.nodes()):\n",
    "        qx=SeqIO.read('clusters/'+i+'.gbk','genbank')\n",
    "        largo=len(qx)\n",
    "        dicyo[i]=largo\n",
    "    sob=max(dicyo.items(), key=operator.itemgetter(1))[0]\n",
    "    print(len(set(list(dicyo.values())))==1)\n",
    "    if len(set(list(dicyo.values())))!=1:\n",
    "        print(dicyo)\n",
    "        print(cou1)\n",
    "        cou1=cou1+1\n",
    "    saved.append(sob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saved2=[]\n",
    "cou2=1\n",
    "for grafos in noncomplete:\n",
    "    dicro={}\n",
    "    for i in list(grafos.nodes()):\n",
    "        qy=SeqIO.read('clusters/'+i+'.gbk','genbank')\n",
    "        largo=len(qy)\n",
    "        dicro[i]=largo\n",
    "    tob=max(dicyo.items(), key=operator.itemgetter(1))[0]\n",
    "    print(len(set(list(dicro.values())))==1)\n",
    "    if len(set(list(dicro.values())))!=1:\n",
    "        print(dicro)\n",
    "        print(cou)\n",
    "        cou2=cou2+1\n",
    "    saved2.append(tob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cou=0\n",
    "saved2=[]\n",
    "for grafos in noncomplete:\n",
    "    if cou!=0:\n",
    "        tmp=grafos.copy()\n",
    "        s=sorted(tmp.degree(), key=lambda x: x[1], reverse=True)\n",
    "        listado=[i[0] for i in s]\n",
    "        for j in listado:\n",
    "            vecinos=list(tmp.neighbors(j))\n",
    "            nodost=list(tmp.nodes())\n",
    "            nodost.remove(j)\n",
    "            if set(vecinos)==set(nodost):\n",
    "                #print(j)\n",
    "                print('si')\n",
    "                saved2.append(j)\n",
    "                break\n",
    "    cou=cou+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dic={}\n",
    "cou=0\n",
    "for grafos in noncomplete:\n",
    "    tmp=grafos.copy()\n",
    "    s=sorted(tmp.degree(), key=lambda x: x[1], reverse=False)\n",
    "    print(s)\n",
    "    saved=[]\n",
    "    bl=[]\n",
    "    for n in s:\n",
    "        bl=list(set(bl+list(tmp.neighbors(n[0]))))\n",
    "        #print(bl)\n",
    "        if not(n[0] in bl):\n",
    "            saved.append(n[0])\n",
    "        tmp.remove_node(n[0])\n",
    "        if iscomplete(tmp):\n",
    "            q=list(set(nx.nodes(tmp))-set(bl))\n",
    "            if q!=[]:\n",
    "                selec=random.choice(q)\n",
    "                saved.append(selec)\n",
    "            print(1)\n",
    "            break\n",
    "        else:\n",
    "            print(0)\n",
    "    dic[cou]=saved\n",
    "    cou=cou+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G=reduce(lambda x,y:nx.compose(x.copy(),y.copy()),noncomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot = Plot(plot_width=800, plot_height=800,\n",
    "            x_range=Range1d(-1.1,1.1), y_range=Range1d(-1.1,1.1))\n",
    "plot.title.text = \"Graph Interaction Demonstration\"\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=[('id','@index'),('contigs','@contigs'),('largo','@largo'),('bacteria','@nombre')]), TapTool(), BoxSelectTool(),SaveTool(),BoxZoomTool(),WheelZoomTool(), PanTool())\n",
    "\n",
    "graph_renderer = from_networkx(gt2, nx.spring_layout, scale=1, center=(0,0))\n",
    "graph_renderer.node_renderer.glyph = Circle(size=10, fill_color='red')\n",
    "graph_renderer.edge_renderer.glyph = MultiLine(line_color=\"#CCCCCC\", line_alpha=0.8, line_width=5)\n",
    "#graph_renderer.selection_policy = EdgesAndLinkedNodes()\n",
    "graph_renderer.inspection_policy = NodesAndLinkedEdges() #\n",
    "plot.renderers.append(graph_renderer)\n",
    "\n",
    "#print(plot.renderers)\n",
    "#li1=LegendItem(label=field('phage'),renderers=[plot.renderers[1].node_renderer])\n",
    "#li2=Legend(items=[li1])\n",
    "#plot.add_layout(li2)\n",
    "\n",
    "output_file(\"interactive_graphs.html\")\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "newedges=a.loc[(~a['Source'].isin(elimin))&(~a['Target'].isin(elimin))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37948"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37757"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newedges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "newedges.to_csv('v2_edges_06_after_cleaning_checkcontrol_dereplication.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenode=pd.read_csv('v2_nodes_after_cleaning_checkcontrol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnodes=filenode.loc[~filenode['Id'].isin(elimin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnodes.to_csv('v2_nodes_after_cleaning_checkcontrol_dereplication.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuyo=[]\n",
    "for tu in newnodes['Id']:\n",
    "    edx=SeqIO.read('clusters/'+tu+'.gbk','genbank')\n",
    "    larg=len(edx)\n",
    "    tuyo.append(larg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnodes2=newnodes.copy()\n",
    "newnodes2['length']=tuyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnodes2.to_excel('v2_nodes_after_cleaning_checkcontrol_dereplication.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pikachu=newnodes['reduccion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pikachu.to_excel('conteo_154genomas+BGC_check_control+dereplication.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pikachu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=[]\n",
    "target=[]\n",
    "for par1,par2 in itertools.combinations(nx.nodes(G),2):\n",
    "    source.append(par1)\n",
    "    target.append(par2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo=pd.DataFrame({'Source':source,'Target':target})\n",
    "nuevo=nuevo.apply(lambda r: sorted(r), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo2=nuevo.merge(a,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo2.columns=['Source','Target','Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=nx.from_pandas_edgelist(nuevo2,source='Source',target='Target',edge_attr='Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpg=sorted(nx.connected_component_subgraphs(zz),key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noto=[]\n",
    "for yu in tmpg:\n",
    "    #print(nx.nodes(yu))\n",
    "    print(nx.get_edge_attributes(yu,'Distance'))\n",
    "    tu=set(nx.get_edge_attributes(yu,'Distance').values())\n",
    "    if len(tu)!=1:\n",
    "        noto.append(yu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2=reduce(lambda x,y:nx.compose(x,y),noto) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neo in [i for i in nx.nodes(tmpg[7])]:\n",
    "    copyfile('anti_folders/clusters/'+neo+'.gbk','transitivity/'+neo+'.gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q=nx.from_pandas_edgelist(tempo95,source='Source',target='Target')\n",
    "listcon=sorted(nx.connected_components(q), key = len, reverse=True)\n",
    "rancho95=[]\n",
    "for i in listcon:\n",
    "    rancho95.append(random.choice(list(i)))\n",
    "forbid95=list(set(list(q.nodes()))-set(rancho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forbid98.pkl', 'wb') as f:\n",
    "    pickle.dump(forbid98, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('forbid95.pkl', 'wb') as f:\n",
    "    pickle.dump(forbid95, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"forbid95.pkl\",\"rb\") as p:\n",
    "    forbid95=pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"forbid98.pkl\",\"rb\") as q:\n",
    "    forbid98=pickle.load(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final95=a.loc[(a['Raw distance']!=0) & (~a['Source'].apply(lambda x:x in forbid95))&(~a['Target'].apply(lambda x:x in forbid95))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final98=a.loc[(a['Raw distance']!=0) & (~a['Source'].apply(lambda x:x in forbid98))&(~a['Target'].apply(lambda x:x in forbid98))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(final98['Source'].append(final98['Target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rancho98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final95.to_csv('final95_0_6.csv',index=False)\n",
    "final98.to_csv('final98_0_6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodos=pd.read_csv('nodes_all_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcaf8=nodos[nodos['Description'].str.contains(\"H-CA\")]['Id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable=nodos.loc[~nodos['Id'].apply(lambda x: x in forbid98)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable.to_csv('nodes_all_modified_derreplicated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty=newtable['reduccion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(newtable['Id'].apply(lambda x: x[0:-11])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty2=nodos['reduccion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datos]",
   "language": "python",
   "name": "conda-env-datos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
